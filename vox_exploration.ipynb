{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stopwords = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vox = pd.read_json('./data/voxtest.jsonl', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = str.maketrans('', '', string.punctuation + '0123456789')\n",
    "stemmer = SnowballStemmer('english')\n",
    "\n",
    "\n",
    "def filter_func(document):\n",
    "    result = []\n",
    "    wordlist = nltk.word_tokenize(document.lower().translate(trans))\n",
    "    for word in wordlist:\n",
    "        c1 = word not in stopwords \n",
    "        c2 = len(word) > 2\n",
    "        c3 = not word.startswith('https')\n",
    "        c4 = not re.match('document[a-z]+', word)\n",
    "        if c1 and c2 and c3 and c4:\n",
    "            result.append(stemmer.stem(word.encode('ascii', 'ignore').decode('UTF-8')))\n",
    "    return result\n",
    "\n",
    "vox['id'] = vox._id.apply(lambda x: x['$oid'])\n",
    "vox.drop('_id', axis=1, inplace=True)\n",
    "vox.text = vox.text.apply(lambda x: filter_func(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = vox.date.apply(lambda x: x[:-1] + 'AM' if x.endswith('a') else x[:-1] + 'PM' if x.endswith('p') else x)\n",
    "y = y.apply(lambda x: x[:12] if x.endswith('M') else x)\n",
    "\n",
    "for row in y.iteritems():\n",
    "    try:\n",
    "        if row[1] == 'NULL':\n",
    "            y[row[0]] = np.nan\n",
    "        else:\n",
    "            y[row[0]] = pd.to_datetime(row[1])\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "vox.date = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/warren/Desktop/programming_projects/news_analysis/news_packages/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:508: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/warren/Desktop/programming_projects/news_analysis/news_packages/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:508: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/warren/Desktop/programming_projects/news_analysis/news_packages/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:508: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/warren/Desktop/programming_projects/news_analysis/news_packages/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:508: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/warren/Desktop/programming_projects/news_analysis/news_packages/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:508: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/warren/Desktop/programming_projects/news_analysis/news_packages/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:508: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/warren/Desktop/programming_projects/news_analysis/news_packages/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:508: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n       estimator=Pipeline(steps=[('tf', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n        strip_a...        random_state=None, topic_word_prior=None,\n             total_samples=1000000.0, verbose=0))]),\n       fit_params={}, iid=True, n_jobs=1,\n       param_grid={'lda__n_topics': (5, 6)}, pre_dispatch='2*n_jobs',\n       refit=True, return_train_score=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "pipeline = Pipeline([\n",
    "  ('tf', CountVectorizer()),\n",
    "  ('lda', LatentDirichletAllocation())\n",
    "])\n",
    "\n",
    "parameters = {\n",
    "  'lda__n_topics': (5, 6)\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(pipeline, parameters)\n",
    "gs.fit(vox.text.apply(lambda x: ' '.join(x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0:\ntrump like peopl one\nTopic #1:\ncoal car oil california\nTopic #2:\ndrug opioid heroin britney\nTopic #3:\nhealth abort insur contracept\nTopic #4:\nmar weiner earth human\n\n"
     ]
    }
   ],
   "source": [
    "def print_top_words(model, feature_names, n_top_words):\n",
    "  for topic_idx, topic in enumerate(model.components_):\n",
    "    print(\"Topic #%d:\" % topic_idx)\n",
    "    print(\" \".join([feature_names[i]\n",
    "                    for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "  print()\n",
    "\n",
    "feature_names = gs.best_estimator_.steps[0][1].get_feature_names()\n",
    "lda = gs.best_estimator_.steps[1][1]\n",
    "print_top_words(lda, feature_names, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt_vct = CountVectorizer()\n",
    "tf = cnt_vct.fit_transform(vox.text.apply(lambda x: ' '.join(x)))\n",
    "\n",
    "\n",
    "\n",
    "def print_top_words(model, feature_names, n_top_words):\n",
    "  for topic_idx, topic in enumerate(model.components_):\n",
    "    print(\"Topic #%d:\" % topic_idx)\n",
    "    print(\" \".join([feature_names[i]\n",
    "                    for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "  print()\n",
    "\n",
    "lda = LatentDirichletAllocation(n_topics=12, max_iter=5,\n",
    "                                learning_method='online',\n",
    "                                learning_offset=50.,\n",
    "                                random_state=0)\n",
    "lda.fit(tf)\n",
    "tf_feature_names = cnt_vct.get_feature_names()\n",
    "print_top_words(lda, tf_feature_names, 8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}